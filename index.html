<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="main.css">
    <title>Master site</title>
</head>
<body>
    
    <main>
<div id="ch1" class="ch">

<h1>Generator</h1>

    <p>

      

        <em>Generator repurposes existing technology to compose new sounds while attempting to pry open the “black box” of machine learning models.</em>   
<br><br>
        <em>Generator</em> is a machine learning algorithm that learned to speak by training on hundreds of samples of bird calls, representing a large variety of different species.
        
        <br><br>
        At the end of each day, the results of the day’s training are fed back into the model as data for the following training session, creating a feedback loop. The result is that , with each successive iteration, the generated samples more accurately reflect the model’s own “acoustical signature”—the pure sonic representation of the high-dimensional abstract space within which the machine processes data. 
        <br><br>
        In this way, an aspect of the training model that would normally remain hidden from view—the latent space in which data is represented—is made sensible through a process of sonification. 
        
        



    </p>

    <br>
    <h2>Listen for the pauses in the soundscape that indicate when the generator is about to sing.</h2>


</div>

<video id="gen" autoplay loop src="vids/white.mp4"></video>


</main>

</body>
</html>